{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Please paste your code into the text file: `code_to_debug.txt`\n",
      "2. Paste the error message you are getting into the text file: `error_message.txt` and then run the next cell\n"
     ]
    }
   ],
   "source": [
    "# Debugging Helper for chatGPT prompting\n",
    "import re\n",
    "preface = \"You are a professional Python developer with experience using VSCode and the libraries:\"\n",
    "mycode = \"\" # code to be debugged\n",
    "libraries = \"\" # libraries used in the code line above, separated by commas extract these using regex\n",
    "libraries = re.findall(r\"import\\s(\\w+)\", mycode.replace('\\n', ' ')) # extract libraries from code above\n",
    "ask = \"Would you mind taking a look at my code below and this error message? -> {} \\n If you are able to fix this issue could you please explain what you did and why it worked? Thank you so much!\"\n",
    "ending = \"\\n\\n Also, if you return any code would you please format it in a code block that I can copy and paste and exclude any docstrings, or comments that are not relevant to the issue? Thank you!\"\n",
    "# ask the user to paste their code into the text file: `code_to_debug.txt` and then run the next cell\n",
    "print(\"1. Please paste your code into the text file: `code_to_debug.txt`\")\n",
    "print(\"2. Paste the error message you are getting into the text file: `error_message.txt` and then run the next cell\")\n",
    "ready = input(\"Are you ready to continue? (y/n)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Would you mind taking a look at my code below and this error message? -> {} \n",
      " If you are able to fix this issue could you please explain what you did and why it worked? Thank you so much!\n",
      "\n",
      "import requests\n",
      "import nltk\n",
      "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
      "from nltk.tokenize import sent_tokenize\n",
      "import seaborn as sns\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# use sentiment analysis in VADER to analyze the sentiment of each chapter of Great Expectations by Charles Dickens. Use the Gutenberg Project API to get the text of the book. Use the nltk library to tokenize the text into sentences. Use the VADER sentiment analyzer to get the sentiment of each sentence. Use the seaborn library to plot the sentiment of each sentence as a swarm plot. Use the matplotlib library to add a title to the plot. Use the matplotlib library to save the plot as a png file.\n",
      "\n",
      "def get_book():\n",
      "    \"\"\"\n",
      "    get_book Use the Gutenberg Project API to get the text of the book.\n",
      "    \"\"\"\n",
      "    #* get the text of the book\n",
      "    book = requests.get('http://www.gutenberg.org/files/1400/1400-0.txt').text\n",
      "    #* return the text\n",
      "    return book\n",
      "\n",
      "def tokenize(book):\n",
      "    \"\"\"\n",
      "    tokenize Use the nltk library to tokenize the text into sentences.\n",
      "    \"\"\"\n",
      "    #* tokenize the text into sentences\n",
      "    sentences = sent_tokenize(book)\n",
      "    #* return the sentences\n",
      "    return sentences\n",
      "\n",
      "def get_sentiment(sentences):\n",
      "    \"\"\"\n",
      "    get_sentiment Use the VADER sentiment analyzer to get the sentiment of each sentence.\n",
      "    \"\"\"\n",
      "    #* initialize the sentiment analyzer\n",
      "    analyzer = SentimentIntensityAnalyzer()\n",
      "    #* initialize a list to hold the sentiment scores\n",
      "    sentiment_scores = []\n",
      "    #* loop over the sentences\n",
      "    for sentence in sentences:\n",
      "        #* get the sentiment score\n",
      "        sentiment_score = analyzer.polarity_scores(sentence)\n",
      "        #* add the score to the list\n",
      "        sentiment_scores.append(sentiment_score)\n",
      "    #* return the list\n",
      "    return sentiment_scores\n",
      "\n",
      "def swarm_plot(sentiment_scores):\n",
      "    \"\"\"\n",
      "    swarm_plot Use the seaborn library to plot the sentiment of each sentence as a swarm plot.\n",
      "    \"\"\"\n",
      "    #* initialize the plot\n",
      "    plt.figure(figsize=(10, 5))\n",
      "    #* make the swarm plot\n",
      "    sns.swarmplot(x='compound', y='sentence', data=sentiment_scores)\n",
      "    #* set the title\n",
      "    plt.title('Sentiment of each sentence in Great Expectations')\n",
      "    #* set the x label\n",
      "    plt.xlabel('Sentiment Score')\n",
      "    #* set the y label\n",
      "    plt.ylabel('Sentence')\n",
      "    #* set the legend\n",
      "    plt.legend(loc='upper right')\n",
      "    #* save the plot\n",
      "    plt.savefig('sentiment.png')\n",
      "    #* show the plot\n",
      "    plt.show()\n",
      "\n",
      "def add_title():\n",
      "    \"\"\"\n",
      "    add_title Use the matplotlib library to add a title to the plot.\n",
      "    \"\"\"\n",
      "    #* add a title to the plot\n",
      "    plt.title('Sentiment of each sentence in Great Expectations')\n",
      "\n",
      "def save_plot():\n",
      "    \"\"\"\n",
      "    save_plot Use the matplotlib library to save the plot as a png file.\n",
      "    \"\"\"\n",
      "    #* save the plot\n",
      "    plt.savefig('greatexpectations_sentmap.png')\n",
      "\n",
      "\n",
      "\n",
      "def great_expectations():\n",
      "    \"\"\"\n",
      "    great_expectations Use sentiment analysis in VADER to analyze the sentiment of each chapter of Great Expectations by Charles Dickens. Use the Gutenberg Project API to get the text of the book. Use the nltk library to tokenize the text into sentences. Use the VADER sentiment analyzer to get the sentiment of each sentence. Use the seaborn library to plot the sentiment of each sentence as a swarm plot. Use the matplotlib library to add a title to the plot. Use the matplotlib library to save the plot as a png file.\n",
      "    \"\"\"\n",
      "    #* get the text of the book\n",
      "    book = get_book()\n",
      "    #* tokenize the text into sentences\n",
      "    sentences = tokenize(book)\n",
      "    #* get the sentiment of each sentence\n",
      "    sentiment_scores = get_sentiment(sentences)\n",
      "    #* plot the sentiment of each sentence as a swarm plot\n",
      "    swarm_plot(sentiment_scores)\n",
      "    #* add a title to the plot\n",
      "    add_title()\n",
      "    #* save the plot as a png file\n",
      "    save_plot()\n",
      "\n",
      "if __name__ == '__main__':\n",
      "    great_expectations()\n",
      "\n",
      " Also, if you return any code would you please format it in a code block that I can copy and paste and exclude any docstrings, or comments that are not relevant to the issue? Thank you!\n"
     ]
    }
   ],
   "source": [
    "with open(\"code_to_debug.txt\", \"r\") as f:\n",
    "    mycode = f.read()\n",
    "with open(\"error_message.txt\", \"r\") as f:\n",
    "    error_message = f.read()\n",
    "# create the prompt\n",
    "prompt = ask + \"\\n\\n\" + mycode + \"\\n\\n \".join(libraries) + ending.format(error_message)\n",
    "print(prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "groupme",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28dd76f97a2595215b3511d9563b8125e93469ee739d17a6b25584482d270cb8"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
